# -*- coding: utf-8 -*-
"""M22AIE251_DLOps_ClassAssignment_2_Q_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wZddDV9rV-kxrwAO5nfFr8hFRqltbRHT
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, random_split
from torch.utils.tensorboard import SummaryWriter
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
import numpy as np

# Define the MLP model
class MLP(nn.Module):
    def __init__(self):
        super(MLP, self).__init__()
        self.fc1 = nn.Linear(28*28, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 10)

    def forward(self, x):
        x = x.view(-1, 28*28)
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# Define the CNN model
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        self.fc1 = nn.Linear(32*7*7, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = torch.max_pool2d(x, kernel_size=2, stride=2)
        x = torch.relu(self.conv2(x))
        x = torch.max_pool2d(x, kernel_size=2, stride=2)
        x = x.view(-1, 32*7*7)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Load and preprocess USPS dataset
transform = transforms.Compose([
    transforms.Resize((28, 28)),  # Resize images to 28x28
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

usps_dataset = torchvision.datasets.USPS(root='./data', train=True, download=True, transform=transform)
train_size = int(0.8 * len(usps_dataset))
test_size = len(usps_dataset) - train_size
train_dataset, test_dataset = random_split(usps_dataset, [train_size, test_size])

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

# Training function
def train(model, train_loader, criterion, optimizer, epoch, writer):
    model.train()
    running_loss = 0.0
    for batch_idx, (data, target) in enumerate(train_loader):
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    writer.add_scalar('training_loss', running_loss / len(train_loader.dataset), epoch)

# Evaluation function
def evaluate(model, test_loader):
    model.eval()
    all_preds = []
    all_targets = []
    with torch.no_grad():
        for data, target in test_loader:
            output = model(data)
            _, preds = torch.max(output, 1)
            all_preds.extend(preds.numpy())
            all_targets.extend(target.numpy())
    accuracy = accuracy_score(all_targets, all_preds)
    precision = precision_score(all_targets, all_preds, average='macro')
    recall = recall_score(all_targets, all_preds, average='macro')
    cm = confusion_matrix(all_targets, all_preds)
    return accuracy, precision, recall, cm

# Setup for TensorBoard
writer = SummaryWriter()

# Training and evaluation loop for MLP
mlp_model = MLP()
mlp_optimizer = optim.Adam(mlp_model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

for epoch in range(10):
    train(mlp_model, train_loader, criterion, mlp_optimizer, epoch, writer)
    accuracy, precision, recall, cm = evaluate(mlp_model, test_loader)
    print(f'MLP Epoch: {epoch}, Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}')
    print('Confusion Matrix:')
    print(cm)

# Training and evaluation loop for CNN
cnn_model = CNN()
cnn_optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)

for epoch in range(10):
    train(cnn_model, train_loader, criterion, cnn_optimizer, epoch, writer)
    accuracy, precision, recall, cm = evaluate(cnn_model, test_loader)
    print(f'CNN Epoch: {epoch}, Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}')
    print('Confusion Matrix:')
    print(cm)

writer.close()